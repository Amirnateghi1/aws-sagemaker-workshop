[
{
	"uri": "/",
	"title": "Amazon SageMaker Workshop",
	"tags": [],
	"description": "",
	"content": "Amazon SageMaker Welcome! Amazon SageMaker is a fully managed service that provides every developer and data scientist with the ability to build, train, and deploy machine learning (ML) models quickly. SageMaker removes the heavy lifting from each step of the machine learning process to make it easier to develop high quality models.\nTraditional ML development is a complex, expensive, iterative process made even harder because there are no integrated tools for the entire machine learning workflow. You need to stitch together tools and workflows, which is time-consuming and error-prone. SageMaker solves this challenge by providing all of the components used for machine learning in a single toolset so models get to production faster with much less effort and at lower cost.\nClick here to get started!\n"
},
{
	"uri": "/workshop/",
	"title": "Amazon SageMaker Workshop",
	"tags": [],
	"description": "Amazon SageMaker Autopilot automatically trains and tunes the best machine learning models for classification or regression, based on your data while allowing to maintain full control and visibility. With SageMaker Autopilot, you provide a tabular dataset and select the target column to predict, which can be a number (such as a house price, called regression), or a category (such as spam/not spam, called classification). SageMaker Autopilot will automatically explore different solutions to find the best model. You then can directly deploy the model to production with just one click, or iterate on the recommended solutions with Amazon SageMaker Studio to further improve the model quality.
In this workshop, we will walk you through the components required to build and train a Machine Learning model using SageMakers new AutoPilot. &lt;br&gt;&lt;br&gt; Let&#39;s get started! &lt;br&gt;&lt;br&gt; &lt;strong&gt;Once all activities are done, please then complete the account cleanup section at the bottom of this page.&lt;/strong&gt;",
	"content": ""
},
{
	"uri": "/specificfeatures/preparedatasets/",
	"title": "Prepare Datasets",
	"tags": [],
	"description": "",
	"content": " Ground Truth Labeling Examples SageMaker Prpcessing Job  "
},
{
	"uri": "/advancedtopics/reinforcementlearning/",
	"title": "Reinforcement Learning",
	"tags": [],
	"description": "",
	"content": " Reinforcemet Learning examples  "
},
{
	"uri": "/sampleproblems/",
	"title": "Sample SageMaker Problems",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/sampleproblems/structureddata/",
	"title": "Structured data",
	"tags": [],
	"description": "",
	"content": " Predicting customer churn using Xgboost Direct marketing Sales prediction Fraud detection Predictive maintenance  "
},
{
	"uri": "/useexistingcode/tensorflow/",
	"title": "Use Existing Tensorflow Code",
	"tags": [],
	"description": "",
	"content": " Tensorflow Script mode Using Horovod with Tensorflow  "
},
{
	"uri": "/specificfeatures/buildtraindeploy/",
	"title": "Build, Train and Deploy models",
	"tags": [],
	"description": "",
	"content": " With SageMaker built-in algorithms With Supported Frameowrks Using the Data Science SDK Using SageMaker Autopilot  "
},
{
	"uri": "/advancedtopics/graphneuralnetworks/",
	"title": "Graph Neural Networks",
	"tags": [],
	"description": "",
	"content": " Deep Graph Library on SageMaker Graph convolutional Networks  "
},
{
	"uri": "/workshop/howitworks/",
	"title": "How Amazon SageMaker Autopilot works",
	"tags": [],
	"description": "Learn how Sagemaker Autopilot Works",
	"content": "Using a single API call, or a few clicks in Amazon SageMaker Studio, SageMaker Autopilot first inspects your data set, and runs a number of candidates to figure out the optimal combination of data preprocessing steps, machine learning algorithms and hyperparameters. Then, it uses this combination to train an Inference Pipeline, which you can easily deploy either on a real-time endpoint or for batch processing. As usual with Amazon SageMaker, all of this takes place on fully-managed infrastructure.\nLast but not least, SageMaker Autopilot also generate Python code showing you exactly how data was preprocessed: not only can you understand what SageMaker Autopilot did, you can also reuse that code for further manual tuning if youâ€™re so inclined.\nAs of today, SageMaker Autopilot supports:\n Input data in tabular format, with automatic data cleaning and preprocessing, Automatic algorithm selection for linear regression, binary classification, and multi-class classification, Automatic hyperparameter optimization, Distributed training, Automatic instance and cluster size selection.  Also see these links for a walkthrough for what we will be doing today:\n AutoML with SageMaker Part 1 AutoML with SageMaker Part 2 AutoML with SageMaker Part 3  "
},
{
	"uri": "/specificfeatures/",
	"title": "Specific SageMaker Features",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/sampleproblems/timeseries/",
	"title": "Time Series",
	"tags": [],
	"description": "",
	"content": " Workshop using GluonTS Time series forecasting using Linear Learner Forecasting electricity usage using DeepAR  "
},
{
	"uri": "/useexistingcode/pytorch/",
	"title": "Use Existing Pytorch Code",
	"tags": [],
	"description": "",
	"content": " Simple example using PyTorch custom code Extending the pytorch container Distributed pytorch using Horovod  "
},
{
	"uri": "/sampleproblems/computervision/",
	"title": "Computer Vision",
	"tags": [],
	"description": "",
	"content": " Image classification Object detection Semantic Segmentation  "
},
{
	"uri": "/advancedtopics/generativeai/",
	"title": "Generative AI",
	"tags": [],
	"description": "",
	"content": " Generative LDA details Generate new text from Wiki data  "
},
{
	"uri": "/workshop/getstarted/",
	"title": "Getting Started",
	"tags": [],
	"description": "In this activity you will either set up SageMaker Studio or a SageMaker notebook instance",
	"content": "To get started, you will need an AWS account. You can either use:\n Your own account; or \u0026hellip; An account provided through Event Engine, as part of an AWS organized workshop   If you are running this workshop as part of an Event Engine lab, please log into the console using this link and enter your hash.\n Otherwise, if you are doing this lab on your own, please follow the following instructions to either:\n Get started with Amazon SageMaker Studio, by following instructions here; or \u0026hellip; Get started with the lab by creating your own notebook instance, as shown here  "
},
{
	"uri": "/specificfeatures/advancedtraining/",
	"title": "Use Advanced Training capabilities",
	"tags": [],
	"description": "",
	"content": " Automatic Model Tuning Manage Experiments with SageMaker Experiments Debug Training jobs with SageMaker Debugger Handling KMS Encrypted data  "
},
{
	"uri": "/useexistingcode/",
	"title": "Use Existing Code",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/useexistingcode/mxnet/",
	"title": "Use Existing MxNet Code",
	"tags": [],
	"description": "",
	"content": " Simple example using MxNet custom code Hosting ONNX models from MxNet using Elastic Inference  "
},
{
	"uri": "/advancedtopics/",
	"title": "Advanced Topics",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/workshop/loadexample/",
	"title": "Load Autopilot Example",
	"tags": [],
	"description": "Start by loading the AutoPilot example on SageMaker",
	"content": "Load Example on Sagemaker Studio   Navigate to the Commands tab - 4th icon on the left (   ) and click \u0026ldquo;Getting Started\u0026rdquo;.   Then click \u0026ldquo;Create Autopilot Experiment\u0026rdquo; - you will see the following window:\n    For Experiment name, enter : Sagemaker-test-autopilot\u0026rdquo; or something similar\n  For S3 location of input data, enter : https://sagemaker-getting-started-data.s3.us-east-2.amazonaws.com/bank-additional-full.csv\n  For Target attribute name, enter : y\n  And for S3 location of output data, enter an s3 location within your account. To create an S3 bucket within your account, use this link. Note : please use us-east-2 for \u0026ldquo;region\u0026rdquo; in step 4 of this guide. If you have an existing bucket in us-east-2 that you would like to use, feel free to do so!\n  Load Example on Sagemaker Notebook Instance  Once you open Jupyter on your SageMaker notebook instance, you can navigate to the \u0026ldquo;SageMaker examples\u0026rdquo; tab  Expand the title \u0026ldquo;Autopilot\u0026rdquo; by clicking it, and then click \u0026ldquo;Use\u0026rdquo;  This will open the Autopilot example:  Make sure you change your Kernel to \u0026ldquo;Conda Python 3\u0026rdquo; if it isn\u0026rsquo;t already set to that.  "
},
{
	"uri": "/sampleproblems/nlp/",
	"title": "Natural Language Processing",
	"tags": [],
	"description": "",
	"content": " Text classification Topic modeling Language modeling using Pytorch  "
},
{
	"uri": "/specificfeatures/advanceddeployment/",
	"title": "Use Advanced Deployment capabilities",
	"tags": [],
	"description": "",
	"content": " Deploy Multi-model Endpoints Deploy Inference Pipelines Monitor models with SageMaker Model Monitor Compile models with SageMaker Neo  "
},
{
	"uri": "/useexistingcode/sklearn/",
	"title": "Use Existing Scikit Learn Code",
	"tags": [],
	"description": "",
	"content": " Scikit Learn end-to-end on SageMaker Bring your own Scikit Learn Container Scikit Learn Multi-model endpoint  "
},
{
	"uri": "/specificfeatures/optimizecosts/",
	"title": "Optimize Costs",
	"tags": [],
	"description": "",
	"content": " Managed spot training with Tensorflow on SageMaker Managed spot training with MxNet on SageMaker Elastic Inference  "
},
{
	"uri": "/workshop/runexample/",
	"title": "Run Autopilot Example",
	"tags": [],
	"description": "Run the AutoPilot example on SageMaker",
	"content": "A typical introductory task in machine learning (the \u0026ldquo;Hello World\u0026rdquo; equivalent) is one that uses a dataset to predict whether a customer will enroll for a term deposit at a bank, after one or more phone calls. For more information about the task and the dataset used, see Bank Marketing Data Set.\nDirect marketing, through mail, email, phone, etc., is a common tactic to acquire customers. Because resources and a customer\u0026rsquo;s attention are limited, the goal is to only target the subset of prospects who are likely to engage with a specific offer. Predicting those potential customers based on readily available information like demographics, past interactions, and environmental factors is a common machine learning problem. You can imagine that this task would readily translate to marketing lead prioritization in your own organization.\nThis example demonstrates how you can use Autopilot on this dataset to get the most accurate ML pipeline through exploring a number of potential options, or \u0026ldquo;candidates\u0026rdquo;. Each candidate generated by Autopilot consists of two steps. The first step performs automated feature engineering on the dataset and the second step trains and tunes an algorithm to produce a model. When you deploy this model, it follows similar steps. Feature engineering followed by inference, to decide whether the lead is worth pursuing or not. The notebook contains instructions on how to train the model as well as to deploy the model to perform batch predictions on a set of leads. Where it is possible, use the Amazon SageMaker Python SDK, a high level SDK, to simplify the way you interact with Amazon SageMaker. Let\u0026rsquo;s explore two ways to run this example:\nRun Example on Sagemaker Studio   Clicking \u0026ldquo;Create Experiment\u0026rdquo; in the previous step will open the following tab   Track the progress of your experiment using the progress bar shown below. In this case, SageMaker Autopilot is done with \u0026ldquo;Analyzing data\u0026rdquo; and the \u0026ldquo;Feature Engineering\u0026rdquo; steps and is currently running \u0026ldquo;Model tuning\u0026rdquo;   The trials tab helps you keep track of training jobs that are completed, in progress and the training job that is the best so far:   To get more details about a particular trial, you can right click on any trial and click \u0026ldquo;Open in Trial details\u0026rdquo;   Click on \u0026ldquo;Objective\u0026rdquo; to sort the trial rows by objective - this will put the best trial on the top   Right-click on the best trial and click \u0026ldquo;Open in Trial component list\u0026rdquo;. Highlight the first 15 rows by holding down ctrl and click through, or by clicking the first row, and clicking on the 15th row while holding down shift. Then click \u0026ldquo;Add chart\u0026rdquo;   Scroll down and click the \u0026ldquo;New Chart\u0026rdquo; area   Under Chart Properties in the right side-bar, select Data type : \u0026ldquo;Summary Statistics\u0026rdquo;, Chart type : \u0026ldquo;Histogram\u0026rdquo; and use the drop-down under X-axis to select validation:accuracy_avg Feel free to explore other charts!\n  In the Trial components list, click any trial followed by \u0026ldquo;Deploy model\u0026rdquo;. Add an endpoint name, and any other optional parameters and click the [Deploy model] button!   (Optional) Enable model monitoring and run through the notebook that opens up. Read more about model monitoring here   Run Example on Sagemaker Notebook Instance   To run cells in your notebook, click a cell followed by the [   Run] button on the top toolbar. You can also click a cell and hit shift+enter\n  Start by running the cells that import necessary packages like sagemaker (python SDK), and set parameters such as region, bucket, prefix and role for later use. Then run the cell the downloads the data.   Read data using padas read_csv   Split the data into a train set and a test dataset   Run the next cell to set up and launch the autopilot job   Run and track the status of the job:   Run the rest of the notebook to get the best candidate job, and to view the \u0026ldquo;Candidate generation\u0026rdquo; and \u0026ldquo;Data exploration\u0026rdquo; notebooks that were generated by SageMaker Autopilot.\n  "
},
{
	"uri": "/sampleproblems/marketplace/",
	"title": "SageMaker Marketplace Examples on SageMaker",
	"tags": [],
	"description": "",
	"content": " AWS Marketplace examples on SageMaker  "
},
{
	"uri": "/useexistingcode/r/",
	"title": "Use Existing R Code",
	"tags": [],
	"description": "",
	"content": " Bring your own R code to SageMaker Using the R Kernel  "
},
{
	"uri": "/useexistingcode/spark/",
	"title": "Using SageMaker Spark",
	"tags": [],
	"description": "",
	"content": " SageMaker Spark Examples  "
},
{
	"uri": "/workshop/cleanup/",
	"title": "Workshop Clean-up",
	"tags": [],
	"description": "Please read through and complete each activity before starting the next.",
	"content": "Please follow the steps below to shutdown or delete resources so you will not be charged.\n  Delete the S3 bucket by selecting the bucket then clicking Delete from above the list of buckets.\n  Delete any notebook instances you may have created.\n  "
},
{
	"uri": "/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/authors/",
	"title": "Credits",
	"tags": [],
	"description": "",
	"content": " Shreyas Subramanian Emily Webber Jeremy Wallace Kimberly Madia  "
},
{
	"uri": "/more_resources/",
	"title": "More Resources",
	"tags": [],
	"description": "",
	"content": "Discover more AWS resources for building and running Machine Learnig projects on Amazon SageMaker:\n  More Hands on Labs\n  Developer resources\n  Youtube - Technical Deep Dive Playlist\n  Edx Course on Sagemaker\n  "
},
{
	"uri": "/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]